<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Classification Trees</title>

<script src="site_libs/header-attrs-2.14/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Home</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    R
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="pivotwider.html">tidyr</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Machine Learning
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="regularized.html">Regularized Linear Models</a>
    </li>
    <li class="dropdown-submenu">
      <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">Trees</a>
      <ul class="dropdown-menu" role="menu">
        <li>
          <a href="trees.html">Decision Trees Concept</a>
        </li>
        <li>
          <a href="classtree.html">Classification Trees</a>
        </li>
      </ul>
    </li>
    <li>
      <a href="pca.html">PCA</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Statistics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="ci.html">Misconceptions About CIs</a>
    </li>
    <li>
      <a href="pvalue.html">P-value</a>
    </li>
    <li>
      <a href="probvslike.html">Probability vs Likelihood</a>
    </li>
    <li>
      <a href="mle.html">MLE</a>
    </li>
    <li>
      <a href="clt.html">Central Limit Theorem</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Classification Trees</h1>

</div>


<style type="text/css">
body {
  font-family: arial;
  font-size: 13pt;
  color: black;
}
</style>
<style> body {text-align: justify} </style>
<p>Now we know what Classification Trees are let’s see how to train and
make predictions. We will use the wine dataset from
<code>sklearn</code></p>
<pre class="python"><code>import pandas as pd
from sklearn.datasets import load_wine
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn import tree
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import classification_report

# Load wine data in numpy array
X, y = load_wine(return_X_y = True)
X.shape # 178 instances

# Check distribution our target</code></pre>
<pre><code>## (178, 13)</code></pre>
<pre class="python"><code>sns.displot(y)

# Split into training set and test set</code></pre>
<p><img src="classtree_files/figure-html/unnamed-chunk-2-1.png" width="244" /></p>
<pre class="python"><code>X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .20, random_state=0)
X_train.shape # 142 instances

# Define our model</code></pre>
<pre><code>## (142, 13)</code></pre>
<pre class="python"><code>dt_classifier = DecisionTreeClassifier(max_depth = 2) 

# Train
dt_classifier.fit(X_train, y_train) </code></pre>
<style>#sk-container-id-10 {color: black;background-color: white;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: "▸";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: "▾";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: "";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: "";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id="sk-container-id-10" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>DecisionTreeClassifier(max_depth=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-10" type="checkbox" checked><label for="sk-estimator-id-10" class="sk-toggleable__label sk-toggleable__label-arrow">DecisionTreeClassifier</label><div class="sk-toggleable__content"><pre>DecisionTreeClassifier(max_depth=2)</pre></div></div></div></div></div>
<p>Note the <code>max_depth</code> hyperparameter from
<code>DecisionTreeClassifier</code> was set to 2. We used 2 arbitrarily
but we could have used <strong>cross validation</strong> to select the
best depth.</p>
<p>With our trained model we can use <code>predict</code> to predict the
classes:</p>
<pre class="python"><code># Predict
y_train_predict = dt_classifier.predict(X_train) </code></pre>
<p>Let’s visualize our tree:</p>
<pre class="python"><code>wine = load_wine()

plt.figure()
tree.plot_tree(
  dt_classifier,
  feature_names = wine.feature_names,
  filled = True, 
  fontsize=6, 
  rounded = True
  )
plt.show()</code></pre>
<p><img src="classtree_files/figure-html/unnamed-chunk-4-3.png" width="672" /></p>
<ul>
<li><code>color_intensity &lt;= 3.82</code>: threshold that separates
into different nodes</li>
<li><code>gini</code>: Gini Impurity</li>
<li><code>samples</code>: number of observations for each node</li>
<li><code>value</code>: number of classifications that fall into each
group</li>
</ul>
<p>We trained our Classification Tree and got our predictions. The last
step is to evaluate our model but how? We use a Confusion Matrix: <img
src="imgs/classtree_img1.png"
alt="Plot from Figrue 6.5 of packtpub.com" /></p>
<p>Let’s assume we have two classes and let 0 be the negative class and
1 the positive class. Each row is an actual class and each column is the
predicted class. Depending on how the classifications were made we
divide them into four different categories:</p>
<ul>
<li><span class="math inline">\(TN =
\frac{correctly~classified~as~negative}{negative~class}\)</span></li>
<li><span class="math inline">\(FP =
\frac{incorrectly~classified~as~positive}{negative~class}\)</span></li>
<li><span class="math inline">\(FN =
\frac{incorrectly~classified~as~negative}{positive~class}\)</span></li>
<li><span class="math inline">\(TP =
\frac{correctly~classified~as~positive}{positive~class}\)</span></li>
</ul>
<p>Next, we discuss three different ways from a confusion matrix to see
how good your classification tree is:</p>
<ul>
<li><p><span class="math inline">\(Accuracy =
\frac{TN+TP}{TN+FP+FN+TP}\)</span></p></li>
<li><p><span class="math inline">\(Precision =
\frac{TP}{FP+TP}\)</span></p></li>
<li><p><span class="math inline">\(Recall =
\frac{TN}{FN+TP}\)</span></p></li>
</ul>
<p>Based on the confusion matrix it seems natural to use Accuracy but
consider the case where we have 9 negative and 1 positive observations
and let’s say there is a silly model that always classifies as negative.
Then the accuracy is 90% (TN: 9, FP: 0, FN: 1, TP: 0 =&gt; <span
class="math inline">\(\frac{9+1}{9+0+1+0}\)</span>). Hence accuracy is
not always a good metric especially when the classes are imbalanced.
This is why we need a better metric like <strong>Precision</strong>. As
you can see from the formula, the denominator takes all predicted cases
both false positive and true positive. Out of these we want to find only
the true positives, hence Precision is the accuracy of the positive
predictions.</p>
<p>However Precision is also not perfect. If we only have one positive
prediction and if that is true positive, then we have 100% Precision
(<span class="math inline">\(\frac{1}{1+0}\)</span>). This is why we
report <strong>Recall</strong> aka <strong>Sensitivity</strong> or
<strong>True Positive Rate</strong> along with Precision. Recall only
differs by the denominator: the number of true positives out of all the
<strong>actual</strong> positive instances.</p>
<p>This is the confusion matrix for our wine data:</p>
<pre class="python"><code>confusion_matrix(y_train, y_train_predict)</code></pre>
<pre><code>## array([[45,  0,  0],
##        [ 2, 46,  7],
##        [ 0,  0, 42]], dtype=int64)</code></pre>
<p>Note that this matrix is 3 by 3 as we have three classes instead of
two. We call this a multi-class classification. We apply the same logic
as we did for 2 by 2 but we just need to break each of the three classes
into positive or negative, respectively. If we assume
<code>class0</code> is positive, then</p>
<ul>
<li><p>TP = classified as <code>class0</code> when the actual is
<code>class0</code> = 45</p></li>
<li><p>FP = classified as <code>class0</code> when the actual is not = 2
+ 0 = 2</p></li>
<li><p>TN = classified as not <code>class0</code> (<code>class1</code>
or <code>class2</code>) when the actual is not = 46 + 7 + 0 + 42 =
95</p></li>
<li><p>FN = classified as not <code>class0</code> when the actual is
<code>class0</code> = 0 + 0 = 0</p></li>
<li><p>Precision = <span
class="math inline">\(\frac{45}{45+2}=0.96\)</span></p></li>
<li><p>Recall = <span
class="math inline">\(\frac{45}{45+0}=1.00\)</span></p></li>
</ul>
<pre class="python"><code>## Evaluation
# Accuracy
accuracy_score(y_train, y_train_predict) </code></pre>
<pre><code>## 0.9366197183098591</code></pre>
<pre class="python"><code>sns.heatmap(confusion_matrix(y_train, y_train_predict), annot = True)
plt.show()</code></pre>
<p><img src="classtree_files/figure-html/unnamed-chunk-6-5.png" width="672" /></p>
<pre class="python"><code>print(classification_report(y_train, y_train_predict, target_names=[&#39;Class 0&#39;, &#39;Class 1&#39;, &#39;Class 2&#39;]))</code></pre>
<pre><code>##               precision    recall  f1-score   support
## 
##      Class 0       0.96      1.00      0.98        45
##      Class 1       1.00      0.84      0.91        55
##      Class 2       0.86      1.00      0.92        42
## 
##     accuracy                           0.94       142
##    macro avg       0.94      0.95      0.94       142
## weighted avg       0.94      0.94      0.94       142</code></pre>
<p><code>macro avg</code> is calculated as the unweighted mean of
f1-scores from each class : <span
class="math inline">\(\frac{0.98+0.91+0.92}{3}=0.94\)</span></p>
<p><code>weighted avg</code> is calculated as the weighted mean of the
number of samples for each class</p>
<p>Now that we we know Precision and Recall, let’s dive in a little bit
deeper. Because there is a trade-off between Precision and Recall,
generally we can’t have both perfect metrics. However there are cases
where we care mostly just about Precision or Recall and it is OK to have
the other showing a low value.</p>
<p>For instance, let’s say there is a COVID-19 testing kit that tells a
potential patient whether or not they have COVID. In this context, a
false positive means even though the patient is COVID negative, the kit
says positive. On the other hand, a false negative means even though the
patient is COVID positive, the kit says negative. Between false positive
and false negative which one do you think is more critical? It would be
false negative as that patient carries the real COVID but will feel
comfortable to hang out simply because the kit says the opposite/healthy
which will result in spreading COVID. On the flip side, it is relatively
OK to have higher false positive because the patient will be cautious
and being cautious will not harm anyone. Hence, we need to have a high
recall but it is OK to have low precision.</p>
<p>Another example would be to test a an AI model tells if a person is
guilty or not. Assuming positive is guilty and negative not guilty,
false positive means even though the person is innocent, the classifier
says guilty. False negative means even though the person is guilty, the
classifier says innocent. Of these two, let’s assume that the
stakeholders considered false positive being the worst case because no
innocent people should be classified as guilty. Hence, we need to have
high precision but it is relatively OK to have low recall.</p>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
